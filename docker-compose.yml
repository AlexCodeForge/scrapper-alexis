version: '3.8'

services:
  # Python Scraper Service
  scraper:
    build:
      context: ./scrapper-alexis
      dockerfile: Dockerfile
    container_name: scraper-alexis-scraper
    restart: unless-stopped
    volumes:
      # Shared data volume for database and images
      - scraper_data:/app/data
      # Logs
      - scraper_logs:/app/logs
      # Screenshots
      - scraper_screenshots:/app/screenshots
      # Debug output
      - scraper_debug:/app/debug_output
      # Avatar cache
      - scraper_avatars:/app/avatar_cache
      # Auth sessions (Playwright)
      - scraper_auth:/app/auth
      # Debug screenshots accessible from web (bind mount to host images/ folder)
      - ./images:/pictures
      # Mount .env file (read-write for settings updates from web container)
      - ./scrapper-alexis/.env:/app/.env
    environment:
      - DISPLAY=:99
      - PYTHONUNBUFFERED=1
      - DATABASE_PATH=/app/data/scraper.db
      - SCREENSHOT_DIR=/app/screenshots
    networks:
      - scraper_network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "cron"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Laravel Web Service
  web:
    build:
      context: ./scrapper-alexis-web
      dockerfile: Dockerfile
    container_name: scraper-alexis-web
    restart: unless-stopped
    ports:
      - "8006:80"
    volumes:
      # Shared data volume (same as scraper)
      - scraper_data:/app/data
      # Shared logs volume (same as scraper) - for live log reading
      - scraper_logs:/scraper/logs:ro
      # Laravel storage
      - web_storage:/var/www/storage
      # Access to scraper scripts and .env file (read-write for settings updates)
      - ./scrapper-alexis:/scraper
      # Shared auth volume (same as scraper) - for file uploads
      - scraper_auth:/app/auth
      # Debug screenshots accessible from web (same bind mount as scraper)
      - ./images:/var/www/html/public/images
      # Docker socket access for container management (restart scraper on settings change)
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - APP_ENV=production
      - APP_DEBUG=false
      - DB_CONNECTION=sqlite
      - DB_DATABASE=/app/data/scraper.db
    depends_on:
      - scraper
    networks:
      - scraper_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

volumes:
  # Shared volume for database and message images
  scraper_data:
    driver: local
  # Scraper logs
  scraper_logs:
    driver: local
  # Scraper screenshots
  scraper_screenshots:
    driver: local
  # Scraper debug output
  scraper_debug:
    driver: local
  # Scraper avatar cache
  scraper_avatars:
    driver: local
  # Scraper auth sessions
  scraper_auth:
    driver: local
  # Web storage
  web_storage:
    driver: local

networks:
  scraper_network:
    driver: bridge

